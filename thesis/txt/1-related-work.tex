
\providecommand{\myrootdir}{..}
\documentclass[\myrootdir/main.tex]{subfiles}

\begin{document}

\chapter{Related Work}
\label{sec:rw}
\todo{introduction \& glue text}
This section presents various research works adjecent or foundational for our work. Starting with studies about Continuous Integration used in software projects, we move on to past works about build log analysis and their augmentation. We differentiate our work from the more common production runtime log analysis and cover different information retrieval techniques. Lastly this section mentions different Programming by Example resources surrounding Microsoft's work on the PROSE library.

\section{Continuous Integration}
\mention{look into proksch papers}
Various researchers have analyzed industrial and open source logs for failure reasons and their impact on development. Seo et al.~\cite{seo2014programmers} found that few error types such as dependency mismatches are the most prominent cause of build failures at Google. In addition most failures are resolved within two builds. Vassallo et al.~\cite{vassallo2017a-tale} compared open source projects in Java to industrial ones. They determined that testing failures outweigh compilation errors. Open source builds fail most often because of unit tests, whereas release preparations is the primary cause in industrial projects. Beller et al.~\cite{beller2017oops} showed that testing is central to continuous integration when evaluating Travis CI logs for Java and ruby builds. They observed very different kinds, failure rates and numbers of test between programming languages and explained that the low failure rates hint at code being tested before it is sent to the CI server.

All these researchers described building parsers in order to evaluate the studied build logs. Our work could support their research by easing the parser development and enable them to cover more languages and build tools easier.

\section{Build Log Analysis and Augmentation}
Vassallo et al.~\cite{vassallo2018un-break} tried to shorten the time it takes developers to understand build logs. They summarized relevant information in Maven build logs and augmented them with links to related stack overflow posts. They observed that highlighting the locality and context of an issue is helpful to programmers. We strive to enable a similar summarization by text retrieval while also covering a wider array of programming languages.
\todo{reference their new paper}

Amar et al.~\cite{amar2019mining} reduced the lines of a log to be inspected by the engineer through removing lines that appear both in passing and failing build logs. They further employed information retrieval techniques to identify the lines most likely hinting at the cause of the error. In contrast to that, our tool ALBE extracts specific parts of the build logs. As this is mostly dependent on the implicit reoccurring structure within the logs we operate on the full log output.

\section{Production Log Analysis}
\mention{logpai and drain, [7] K. Fisher and D. Walker. The pads project: an overview. In ICDT,
2011.
[8] K. Fisher, D. Walker, K. Q. Zhu, and P. White. From dirt to shovels:
fully automatic tool generation from ad hoc data. In POPL, 2008.[23] Q. Xi and D. Walker. A context-free markup language for semi- structured text. In PLDI, pages 221–232, 2010.
 The PADS project [7] has en- abled simplification of ad hoc data processing tasks for programmers
accounts addresses split chairs awk banks companies countries hadoop horses instruments ls-l mgx namephone nozzle numbertext papers pldi12 pldi13 pop13 quotes speechbench techfest ucla-faculty users
accounts addresses split chairs awk banks companies countries hadoop horses instruments ls-l mgx namephone nozzle numbertext papers pldi12 pldi13 pop13 quotes speechbench techfest ucla-faculty users
abt amazon apple barnes bestbuy bigtray bol buy cameraword cnet cooking-bw dealtime drugstore ebay mgzoutlet mediaworld nthbutsw powells googlepdct yahooshop shopping shopzilla target tigerdirect venere
abt amazon apple barnes bestbuy bigtray bol buy cameraword cnet cooking-bw dealtime drugstore ebay mgzoutlet mediaworld nthbutsw powells googlepdct yahooshop shopping shopzilla target tigerdirect venere
hg_ex12 hg_ex18 hg_ex2 hg_ex26 hg_ex29 hg_ex3 hg_ex39 _h8d62ck1* 03PFMJOU* 2003Fall 64040 anrep9899* bali ch15_e compliance* DataDiction* deliverable* e_Bubble_* flip_usd5 Funded - F ge-revenues HOSPITAL* pwpSurvey* SOA4-YEAR* young_table
hg_ex12 hg_ex18 hg_ex2 hg_ex26 hg_ex29 hg_ex3 hg_ex39 _h8d62ck1* 03PFMJOU* 2003Fall 64040 anrep9899* bali ch15_e compliance* DataDiction* deliverable* e_Bubble_* flip_usd5 Funded - F ge-revenues HOSPITAL* pwpSurvey* SOA4-YEAR* young_table
seconds
# examples
seconds
examples
seconds
examples
by contributing along several dimensions: development of domain specific languages for describing text structure or data format, learn- ing algorithms for automatically inferring such formats [8], and a markup language to allow users to add simple annotations to enable more effective learning of text structure [23] While PADS supports parsing of entire files, FlashExtract allows users to extract only parts of the file thereby avoiding unnecessary complications. PADS’s learner only supports a fixed line-by-line chunking strategy to split the records; in contrast, FlashExtract can learn chunking (aka, struc- ture boundaries) from examples, making it suitable for extracting data fields and records that have arbitrary length (and might cross multiple lines). Finally, PADS primarily targets ad hoc text files. Although one can view webpages and spreadsheet as text files, it is unclear if the PADS learning algorithm can be adapted to work effectively for webpages and spreadsheets.
}

\mention{ask Jean?}

\section{Information retrieval and Retrieval Techniques}
\review{Getting the general topic or conceptual information of a text is a common task in information retrieval from semi-structured text sources. Usually this is done by preprocessing the documents, transforming them to a term-by-document matrix. On the matrix we apply a similarity comparison like for example vector space models to calculate the similarity of the different documents to each other~\cite{panichella2016parameterizing}. For our use case, this could be applied by slicing the build logs into lines or small sections. Then similarity measures are used to compare the overall topics in these subparts to the topic of previously labelled logparts.
Instead of receiving a paragraph which is similar to a given query, our works focus more on obtaining specific pieces of texts through regular expressions.}



\mention{IR papers, maybe something about keyword search?}

\section{Program Synthesis by Example}
\todo{how much can/should we explain here? possibly big parts are already explained in related work: vsa, divied and coquer, witness functions, enumeration and ranking (prose theory paper), flash extract specifics like what functions they have (absolute pos, pre/post regex), rankings specific to ci biulg logs?}
\review{
Le et al.~\cite{le2014flashextract:} developed FlashExtract as part of the \emph{Microsoft Program Synthesis using Examples} (PROSE) framework. It is a tool which synthesizes text extraction programs from semi-structured text based on a few given examples. Users can extract multiple fields and structure them with hierarchy and sequence. FlashExtract eliminates the need for the user to understand the entire structure of the processed document and the effort of developing a suitable extraction program themselves.

We are applying FlashExtract to the domain of build logs, using programming by example to take away the need to tediously develop and maintain regular expressions for information retrieval.
}
\mention{prose theory paper \cite{polozov2015flashmeta:}}
\mention{\cite{rolim2017learning}}

\end{document}
